{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOyqYHTk_Q57"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_YHJjnD_Tja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgC61-ah_WIz"
   },
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(store_data, train_data, test_data):\n",
    "    # import datasets\n",
    "    store = pd.read_csv(\n",
    "        store_data,\n",
    "        dtype={\n",
    "            \"Store\": \"Int64\",\n",
    "            \"StoreType\": \"object\",\n",
    "            \"Assortment\": \"object\",\n",
    "            \"CompetitionDistance\" : \"Int64\",\n",
    "            \"CompetitionOpenSinceMonth\": \"Int64\",\n",
    "            \"CompetitionOpenSinceYear\": \"Int64\",\n",
    "            \"Promo2\": \"Int64\",\n",
    "            \"Promo2SinceWeek\": \"Int64\",\n",
    "            \"Promo2SinceYear\": \"Int64\",\n",
    "            \"PromoInterval\": \"object\",\n",
    "            \"StateHoliday\": \"object\"\n",
    "        })\n",
    "    train = pd.read_csv(\n",
    "        train_data,\n",
    "        dtype={\n",
    "            \"Store\": \"Int64\",\n",
    "            \"DayOfWeek\": \"Int64\",\n",
    "            \"Date\": \"object\",\n",
    "            \"Sales\": \"Int64\",\n",
    "            \"Customers\": \"Int64\",\n",
    "            \"StateHoliday\": \"object\",\n",
    "            \"SchoolHoliday\": \"Int64\"\n",
    "        })\n",
    "    test = pd.read_csv(\n",
    "        test_data,\n",
    "        dtype={\n",
    "            \"Id\": \"Int64\",\n",
    "            \"Store\": \"Int64\",\n",
    "            \"DayOfWeek\": \"Int64\",\n",
    "            \"Date\": \"object\",\n",
    "            \"Open\": \"Int64\",\n",
    "            \"Promo\": \"Int64\",\n",
    "            \"StateHoliday\": \"object\",\n",
    "            \"SchoolHoliday\": \"Int64\"\n",
    "        })\n",
    "    \n",
    "    return store, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_store(store, train, test):\n",
    "    # merge the store_train and store_test dataset into the train and test dataset\n",
    "    train = pd.merge(left=store, right=train, how='inner', left_on='Store', right_on='Store')\n",
    "    test = pd.merge(left=store, right=test, how='inner', left_on='Store', right_on='Store')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat types and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_date(data):\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['Year'] = data.Date.dt.year\n",
    "    data['Month'] = data.Date.dt.month\n",
    "    data['Day'] = data.Date.dt.day\n",
    "    data['WeekOfYear'] = data.Date.dt.isocalendar().week\n",
    "    data = data.drop(['Date'],axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date column\n",
    "def treat_data(data):\n",
    "    data = data.rename(columns={\"Store\": \"StoreId\"})\n",
    "    data = split_date(data)\n",
    "    data['StateHoliday'] = data['StateHoliday'].apply(lambda x: 0 if x.isnumeric() else ord(x) - 64)\n",
    "    data['CompetitionOpenSinceMonth'] = pd.to_datetime(data['CompetitionOpenSinceMonth']).dt.month\n",
    "    data['CompetitionOpenSinceYear'] = pd.to_datetime(data['CompetitionOpenSinceYear']).dt.year\n",
    "    data['Promo2SinceYear'] = pd.to_datetime(data['Promo2SinceYear']).dt.year\n",
    "    data['DayOfWeek'] = pd.to_datetime(data['DayOfWeek']).dt.day\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into feature and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_feature_label(train, label_column_name):\n",
    "    X_train = train.drop([label_column_name], axis = 1)\n",
    "    y_train = train[label_column_name]\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dummy(data, column_name):\n",
    "    # use dummie variable to replace the PromoInterval column\n",
    "    supported_columns = data[column_name].str.get_dummies(',').columns\n",
    "    data_categories = data[column_name].str.get_dummies(',').filter(supported_columns)\n",
    "    data = data.drop([column_name],axis = 1).join(data_categories)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(data, column_name):\n",
    "    le = LabelEncoder()\n",
    "    data[column_name] = le.fit_transform(data[column_name])\n",
    "    \n",
    "    pickle.dump(le, open('deploy/label_encoder.pkl', 'wb'))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_one_hot(data, column_name):\n",
    "    encoder=OneHotEncoder(sparse=False)\n",
    "    data_encoded = pd.DataFrame (encoder.fit_transform(data[[column_name]]))\n",
    "    data_encoded.columns = encoder.get_feature_names([column_name])\n",
    "    data.drop([column_name] ,axis=1, inplace=True)\n",
    "    data= pd.concat([data, data_encoded ], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_data(data):\n",
    "    return data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numerical_mean(data):\n",
    "    # replace all missing values by the mean in the column\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputer.fit(data)\n",
    "    output = imputer.transform(data)\n",
    "    data = pd.DataFrame(output, columns = data.columns)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export csv of treated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float_to_int(data):\n",
    "    for x in data.columns.tolist():\n",
    "        data[x] = np.floor(pd.to_numeric(data[x], errors='coerce')).astype('Int64')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(X_train, y_train, X_test):\n",
    "    data = pd.concat([X_train, y_train ], axis=1)\n",
    "    \n",
    "    X_test = X_test.drop(columns=['Id'],axis=1)\n",
    "    data = data.drop(columns=['Customers'],axis=1)\n",
    "    \n",
    "    data.to_csv('preprocessed_data/data.csv')\n",
    "    X_test.to_csv('preprocessed_data/X_pred.csv')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find last date with known sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # load\n",
    "    store_data = 'original_data/store.csv'\n",
    "    train_data = 'original_data/train.csv'\n",
    "    test_data = 'original_data/test.csv'\n",
    "    store, train, test = get_data(store_data, train_data, test_data)\n",
    "\n",
    "    # merge\n",
    "    train, test = merge_store(store, train, test)\n",
    "\n",
    "    # treat\n",
    "    train = treat_data(train)\n",
    "    test =  treat_data(test)\n",
    "\n",
    "    # feature and label\n",
    "    X_train, y_train = split_feature_label(train, 'Sales')\n",
    "    X_test = test\n",
    "\n",
    "    # encoding\n",
    "    # encode dummy varibles for column with multiple values\n",
    "    X_train = encode_dummy(X_train, 'PromoInterval')\n",
    "    X_test = encode_dummy(X_test, 'PromoInterval')\n",
    "    # encode label\n",
    "    X_train = encode_label(X_train, 'Assortment')\n",
    "    X_test = encode_label(X_test, 'Assortment')\n",
    "    # encode one hot\n",
    "    X_train = encode_one_hot(X_train, 'StoreType')\n",
    "    X_test = encode_one_hot(X_test, 'StoreType')\n",
    "\n",
    "    # missing data\n",
    "    X_train = replace_numerical_mean(X_train)\n",
    "    X_test = replace_numerical_mean(X_test)\n",
    "\n",
    "    # convert data types before exporting\n",
    "    y_train = pd.DataFrame(data=y_train)\n",
    "    X_train = convert_float_to_int(X_train)\n",
    "    X_test = convert_float_to_int(X_test)\n",
    "\n",
    "    # export preprocessed data\n",
    "    export_csv(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKgdwz54xQOEOK5GD93nk2",
   "collapsed_sections": [],
   "name": "Copy of multiple_linear_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
